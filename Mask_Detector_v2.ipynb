{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 Removes face tracking due to erroneous.\n",
    "# fix for face tracking will be for v3\n",
    "\n",
    "# Class Files\n",
    "from imutils.video import VideoStream\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN\n",
    "from fastai.vision import *\n",
    "import youtube_dl\n",
    "import imutils\n",
    "import pathlib\n",
    "import scipy.misc\n",
    "import uuid\n",
    "from multiprocessing import Process, Manager, Queue\n",
    "import multiprocessing as mp\n",
    "import dlib\n",
    "\n",
    "#Class for a Mask Predictor\n",
    "class maskPredictor_fastai:\n",
    "    def __init__(self):\n",
    "        #defaults.device = torch.device('cpu')\n",
    "        classes = ['noMask','withMask']\n",
    "        path = 'C:/Projects/Mask Detector/train_data'\n",
    "        \n",
    "        #Create blank databunch\n",
    "        data2 = ImageDataBunch.single_from_classes(path, classes, ds_tfms=get_transforms(), size=128).normalize(imagenet_stats)\n",
    "        \n",
    "        #Create the learner\n",
    "        learn = cnn_learner(data2, models.resnet34, metrics=error_rate)\n",
    "        #Load it with the pretrained RESNET Weights \n",
    "        #'res34_stage2_1 best one yet\n",
    "        #'res50_stage1_v3 best one yet\n",
    "        learn.load('res34_stage1_v1')\n",
    "        #learn.load('vgg19_stage1_v1')\n",
    "        self.model = learn\n",
    "        \n",
    "    def maskPredict(self,face):\n",
    "        img = Image(pil2tensor(face, dtype=np.float32).div_(255))\n",
    "         \n",
    "        tic = time.perf_counter() \n",
    "        #Make prediction\n",
    "        while True:\n",
    "            try:\n",
    "                 \n",
    "                pred_class,pred_idx,outputs = self.model.predict(img)\n",
    "                score = outputs.max()\n",
    "                break\n",
    "                \n",
    "            except ZeroDivisionError:\n",
    "                print('Computation Error')\n",
    "                score = 0\n",
    "                pred_idx = 0\n",
    "                return None\n",
    "        toc = time.perf_counter()       \n",
    "        \n",
    "        print(f\"Mask Inference:{toc - tic:0.4f}s\")\n",
    "                \n",
    "        return score, pred_idx\n",
    "        \n",
    "#class for Face Detection using FastMTCNN\n",
    "class FastMTCNN(object):\n",
    "    \"\"\"Fast MTCNN implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, stride, resize=1, *args, **kwargs):\n",
    "        self.stride = stride\n",
    "        self.resize = resize\n",
    "        self.mtcnn = MTCNN(*args, **kwargs)\n",
    "    \n",
    "    def __call__(self, frames):\n",
    "        #print(\"I, FastMTCNN, have been called\")\n",
    "        if self.resize != 1:\n",
    "            frames = cv2.resize(frames, (int(frames.shape[1] * self.resize), int(frames.shape[0] * self.resize)))\n",
    "        \n",
    "        #results = self.mtcnn.detect(frames[::self.stride])\n",
    "        tic= time.time() \n",
    "        boxes, results = self.mtcnn.detect(frames, landmarks=False)\n",
    "        toc=time.time()\n",
    "    \n",
    "        #print('Face Detection Inference is:' + str(toc-tic))\n",
    "        return [boxes, results]\n",
    "\n",
    "\n",
    "#class for Face Detection using Standard MTCNN    q    \n",
    "class stdMTCNN(object):  \n",
    "    def __init__(self, resize=1, *args, **kwargs):\n",
    "        self.resize = resize\n",
    "        self.mtcnn = MTCNN(*args, **kwargs)\n",
    "    \n",
    "    def __call__(self, frames):\n",
    "        if self.resize != 1:\n",
    "            frames = cv2.resize(frames, (int(frames.shape[1] * self.resize), int(frames.shape[0] * self.resize)))\n",
    "        \n",
    "        #results = self.mtcnn.detect(frames[::self.stride])\n",
    "        tic= time.time() \n",
    "        boxes, results = self.mtcnn.detect(frames, landmarks = False)\n",
    "        toc=time.time()\n",
    "        print('Face Detection Inference is:' + str(toc-tic))\n",
    "        \n",
    "        return [boxes, results]\n",
    "\n",
    "#Load in prediction Functions\n",
    "\n",
    "### Face\n",
    "def detect_face(frame, faceNet, draw = True):\n",
    "    # initialize our results list\n",
    "    results = []\n",
    "    \n",
    "    #The higher the better face detections works\n",
    "    img_size = 300\n",
    "    \n",
    "    if (frame is None):\n",
    "        print('No frame detected')\n",
    "        return None\n",
    "    # grab the dimensions of the frame and then construct a blob\n",
    "    (h, w) = frame.shape[:2]\n",
    "    \n",
    "    # pass the blob through the network and obtain the face detections\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (img_size, img_size),(104.0, 177.0, 123.0))\n",
    "    # Pass frame through Input\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with\n",
    "        # the prediction\n",
    "        confidence = detections[0, 0, i, 2] \n",
    "        minConf = 0.6 \n",
    "        # filter out weak detections by ensuring the confidence is\n",
    "        # greater than the minimum confidence\n",
    "        #compute the (x, y)-coordinates of the bounding box for\n",
    "\n",
    "        if confidence > minConf:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            #Detect if any negative values and turn to 0\n",
    "            box[box < 0] = 1\n",
    "            \n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            #Store results of face coordinates\n",
    "            d = [startX, startY, endX, endY]\n",
    "            \n",
    "            \n",
    "        \n",
    "            #Draw rectangle around face\n",
    "            if draw is True:\n",
    "                cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 0, 255), 2)\n",
    "            #In cases that there are more than one face per frame, it appends to a list\n",
    "            d = [startX, startY, endX, endY]\n",
    "            \n",
    "            if any(t < 0 for t in d):\n",
    "                for i,p in enumerate(d):\n",
    "                    print (i)\n",
    "                    if d[i] < 0:\n",
    "                        d[i] = 0\n",
    "            results.append(d)       \n",
    "    return results\n",
    "\n",
    "def detect_face_MTCNN(frame, faceNet, draw = True):\n",
    "    results = []\n",
    "  \n",
    "    if (frame is None):\n",
    "        print('No frame detected')\n",
    "        return None\n",
    "    \n",
    "    (h, w) = frame.shape[:2]\n",
    "    pad_f = 0.05\n",
    "\n",
    "    \n",
    "    frame_p = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    minConf = 0.5\n",
    "    \n",
    "\n",
    "#Check if any objects are tracked; If none, conduct a detect Face Algorithm\n",
    "\n",
    "    #Pass frame through network and come out with bounding box in (face)\n",
    "    #We do the predictions here\n",
    "    [face, score] = faceNet(frame_p)\n",
    "    if (face is None or face.size == 0):\n",
    "        print('No face detected')\n",
    "        cv2.imshow('frame',frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        return None\n",
    "\n",
    "    #Change negative values to 0 (Bug in in the model)\n",
    "    face[face < 0] = 0\n",
    "\n",
    "    #Resize facebounding box to original size\n",
    "    if faceNet.resize != 1:\n",
    "        face = np.multiply(face,(1/faceNet.resize))\n",
    "\n",
    "    #For each detected face\n",
    "    for i in range(0, face.shape[0]):\n",
    "\n",
    "        #Check if results is more thatn confidence\n",
    "        if score[i] > minConf:\n",
    "            # Unpack\n",
    "            (startX, startY, endX, endY) = face[i].astype(int)\n",
    "\n",
    "            pad_x = int((endX-startX) * pad_f)\n",
    "            pad_y = int((endY-startY) * pad_f)\n",
    "\n",
    "            #Draw rectangle around face\n",
    "            if draw:\n",
    "                cv2.rectangle(frame, (startX-pad_x, startY-pad_y), (endX+pad_x, endY+pad_y),(0, 0, 255), 2)\n",
    "\n",
    "            d = [startX-pad_x, startY-pad_y, endX+pad_x, endY+pad_y]\n",
    "            #d = [startX, startY, endX, endY]\n",
    "            results.append(d)\n",
    "\n",
    " \n",
    "        \n",
    "    return results\n",
    "    \n",
    "\n",
    "### MASK\n",
    "def detect_mask(face_box, frame, maskNet, save, minConf = 0.8, draw = True):\n",
    "    pred_dict = {0: 'No Mask',1: 'With Mask'}\n",
    "    results = []\n",
    "    p = 0\n",
    "    \n",
    "   #Check if face has data\n",
    "    if [x for x in (face_box, frame) if x is None]:\n",
    "        print('No face detected 1')\n",
    "        return None\n",
    "    \n",
    "    #Iterate over the returned results\n",
    "    for i in face_box:\n",
    "        (startX, startY, endX, endY) = face_box[p]\n",
    "        p = p+1\n",
    "        #Crop out just the face from the frame\n",
    "        face = frame[startY:endY, startX:endX]\n",
    "        if [x for x in (face, frame) if x is None]:\n",
    "            print('No face detected 2')\n",
    "            return None\n",
    "        \n",
    "        #Pass through Mask Detector Model and Time\n",
    "        mask_results = maskNet.maskPredict(face = face)\n",
    "        \n",
    "        if mask_results is None:\n",
    "            return None\n",
    "\n",
    "        #Get results from tensors and convert to a list\n",
    "        d = [mask_results[1].item(), mask_results[0].item()]\n",
    "\n",
    "        #Only annotate ones which have a good confidence\n",
    "        if d[1] > minConf:\n",
    "        \n",
    "        #Script for saving image in folder\n",
    "            if save:\n",
    "                print('called')\n",
    "                size = (224, 224)\n",
    "                face = cv2.resize(face, size)\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_RGB2BGR)\n",
    "                im = Image.fromarray(face)\n",
    "\n",
    "                if d[0] == 1:#If Face has Mask\n",
    "                    outfile = '%s/%s.jpg' % ('train_data/withMask', 'withMask' + str(uuid.uuid4()))\n",
    "                    im.thumbnail(size)\n",
    "                    im.save(outfile)\n",
    "                    print('saved image')\n",
    "                elif d[0] == 0: #If face has noMask\n",
    "                    outfile = '%s/%s.jpg' % ('train_data/noMask', 'noMask' + str(uuid.uuid4()))\n",
    "                    im.thumbnail(size)\n",
    "                    im.save(outfile)\n",
    "                    print('saved image')\n",
    "\n",
    "            #Annotate if draw is True\n",
    "            if draw:\n",
    "\n",
    "                #Change color of text according to results\n",
    "                if d[0] == 1:\n",
    "                    text_color = (0,255,0)\n",
    "                elif d[0] == 0:\n",
    "                    text_color = (0,0,255)\n",
    "\n",
    "                text = \"{}: {:.2f}%\".format(pred_dict[d[0]], d[1] * 100)\n",
    "                y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "                cv2.putText(frame, text, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, text_color, 2)\n",
    "\n",
    "        results.append(d)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing A Webcam Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import scipy.misc\n",
    "import uuid\n",
    "import os\n",
    "import imutils\n",
    "\n",
    "\n",
    "class WebCamPlayer:    \n",
    "    def __init__(self, faceNet='ResCaffe'):\n",
    "        print(\"Initializing\")\n",
    "        #Load Predict setup files\n",
    "        current_dir = pathlib.Path().absolute()\n",
    "        \n",
    "        #Choosing the face Detection System\n",
    "        if faceNet == 'ResCaffe':\n",
    "            #Load up hass Face Detector    \n",
    "            prototxtPath =  os.path.join(current_dir,'face_detector','deploy.prototxt')\n",
    "            weightsPath = os.path.join(current_dir,'face_detector','res10_300x300_ssd_iter_140000.caffemodel')\n",
    "            faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "            self.faceNetType = 'ResCaffe' \n",
    "        \n",
    "        elif faceNet == 'SFD':\n",
    "            #Load up hass SFD Detector   \n",
    "            prototxtPath =  os.path.join(current_dir,'face_detector','deploy_sfd.prototxt')\n",
    "            weightsPath = os.path.join(current_dir,'face_detector', 'SFD.caffemodel')\n",
    "            faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "            self.faceNetType = 'SFD' \n",
    "        \n",
    "        elif faceNet == 'fastMTCNN':\n",
    "            faceNet = FastMTCNN(\n",
    "                stride=4,\n",
    "                resize=0.5,\n",
    "                margin=14,\n",
    "                factor=0.6,\n",
    "                keep_all=True,\n",
    "                select_largest=False,\n",
    "                device='cpu'\n",
    "            )\n",
    "            self.faceNetType = 'fastMTCNN'\n",
    "            self.resize = faceNet.resize\n",
    "            \n",
    "        elif faceNet == 'stdMTCNN':\n",
    "            faceNet = stdMTCNN(\n",
    "                select_largest=False,\n",
    "                resize=0.5,\n",
    "                margin=20,\n",
    "                factor=0.6,\n",
    "                keep_all=True,\n",
    "                device='cpu'\n",
    "            )\n",
    "            self.faceNetType = 'stdMTCNN'\n",
    "            self.resize = faceNet.resize\n",
    "            \n",
    "        print(str(self.faceNetType)+' initialized as the Detection')\n",
    "        #Choosing the Mask Detection Version\n",
    "        maskNet = maskPredictor_fastai()\n",
    "        \n",
    "        self.faceNet = faceNet\n",
    "        self.maskNet = maskNet\n",
    "        \n",
    "    \n",
    "    def webcam_play(self, detect = True, draw = True, save = False, skip_frames = 0):\n",
    "        vs = VideoStream(src=1).start()\n",
    "        print(\"Starting Web Cam Feed\")\n",
    "        time.sleep(2.0)\n",
    "        frame_count = 0\n",
    "        M = 0\n",
    "        while True:\n",
    "            frame_count = frame_count + 1\n",
    "            # grab the frame from the video stream\n",
    "            # to have a maximum width of 400 pixels\n",
    "            frame = vs.read()\n",
    "            \n",
    "            if (frame is None):\n",
    "                print('No frame detected')\n",
    "                break\n",
    "            #Resize The frame\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "\n",
    "            #Script to only apply detection after N frames if skip_Frames is not set to 0\n",
    "            if not skip_frames == 0:\n",
    "                M = frame_count % skip_frames\n",
    "\n",
    "            if detect and M==0:\n",
    "                if self.faceNetType in ['ResCaffe','SFD']:\n",
    "                    face_box = detect_face(frame, self.faceNet)\n",
    "                    if face_box is None:\n",
    "                        continue\n",
    "                    results = detect_mask(face_box, frame, self.maskNet,save)\n",
    "\n",
    "                elif self.faceNetType in ['fastMTCNN','stdMTCNN']:\n",
    "                    face_box = detect_face_MTCNN(frame, self.faceNet, draw)\n",
    "                    if face_box is None:\n",
    "                        continue\n",
    "                    results = detect_mask(face_box, frame, self.maskNet,save)\n",
    "\n",
    "            # display frame\n",
    "            cv2.namedWindow(\"frame\")\n",
    "            cv2.imshow('frame', frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord(\"q\"):\n",
    "                break\n",
    "                    \n",
    "        # release VideoCapture\n",
    "        vs.stop()\n",
    "        vs.stream.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu device type at start of device string: device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-acfca51a0aa1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWebCamPlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'stdMTCNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebcam_play\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-bef57e2e6ddb>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, faceNet)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mkeep_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             )\n\u001b[0;32m     53\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfaceNetType\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'stdMTCNN'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-b6ca4a90dbf8>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, resize, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmtcnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\facenet_pytorch\\models\\mtcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, image_size, margin, min_face_size, thresholds, factor, post_process, select_largest, keep_all, device)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \"\"\"\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m         \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected one of cpu, cuda, mkldnn, opengl, opencl, ideep, hip, msnpu device type at start of device string: device"
     ]
    }
   ],
   "source": [
    "vid = WebCamPlayer(faceNet = 'stdMTCNN')\n",
    "vid.webcam_play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cc51cf901492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vs' is not defined"
     ]
    }
   ],
   "source": [
    "vs.stop()\n",
    "vs.stream.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class vidPlayer:\n",
    "    def __init__(self, video_url, faceNet='ResCaffe'):\n",
    "        print(\"Initializing\")\n",
    "        #Load Predict setup files\n",
    "        current_dir = pathlib.Path().absolute()\n",
    "        \n",
    "        #Choosing the face Detection System\n",
    "        if faceNet == 'ResCaffe':\n",
    "            #Load up hass Face Detector    \n",
    "            prototxtPath =  os.path.join(current_dir,'face_detector','deploy.prototxt')\n",
    "            weightsPath = os.path.join(current_dir,'face_detector','res10_300x300_ssd_iter_140000.caffemodel')\n",
    "            faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "            self.faceNetType = 'ResCaffe' \n",
    "        \n",
    "        elif faceNet == 'SFD':\n",
    "            #Load up hass SFD Detector   \n",
    "            prototxtPath =  os.path.join(current_dir,'face_detector','deploy_sfd.prototxt')\n",
    "            weightsPath = os.path.join(current_dir,'face_detector', 'SFD.caffemodel')\n",
    "            faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "            self.faceNetType = 'SFD' \n",
    "        \n",
    "        elif faceNet == 'fastMTCNN':\n",
    "            faceNet = FastMTCNN(\n",
    "                stride=4,\n",
    "                resize=0.5,\n",
    "                margin=14,\n",
    "                factor=0.6,\n",
    "                keep_all=True,\n",
    "                select_largest=False,\n",
    "                device='cpu'\n",
    "            )\n",
    "            self.faceNetType = 'fastMTCNN'\n",
    "            self.resize = faceNet.resize\n",
    "            \n",
    "        elif faceNet == 'stdMTCNN':\n",
    "            faceNet = stdMTCNN(\n",
    "                select_largest=False,\n",
    "                resize=0.25,\n",
    "                margin=20,\n",
    "                factor=0.6,\n",
    "                keep_all=True,\n",
    "                post_process = False,\n",
    "                device='cpu'\n",
    "            )\n",
    "            self.faceNetType = 'stdMTCNN'\n",
    "            self.resize = faceNet.resize\n",
    "            \n",
    "        print(str(self.faceNetType)+' initialized as the Detection')\n",
    "        #Choosing the Mask Detection Version\n",
    "        maskNet = maskPredictor_fastai()\n",
    "        \n",
    "        self.faceNet = faceNet\n",
    "        self.maskNet = maskNet\n",
    "        \n",
    "        #Video URL\n",
    "        self.video_url = video_url\n",
    "        \n",
    "    \n",
    "    def youtube_play(self, detect = True, draw = True, save = False, skip_frames = 0, save_vid = False):\n",
    "        #ydl_opts = {'no_check_certificate': True}      #Additional options for video stream\n",
    "        ydl_opts = {}\n",
    "        ydl = youtube_dl.YoutubeDL(ydl_opts)                           # create youtube-dl object\n",
    "        info_dict = ydl.extract_info(self.video_url, download=False)         # set video url, extract video information\n",
    "\n",
    "        # get video formats available\n",
    "        formats = info_dict.get('formats',None)\n",
    "\n",
    "        for f in formats:\n",
    "            \n",
    "            # Set Resolution\n",
    "            #if f.get('format',None) == '720p':\n",
    "            if f.get('format_note',None) == '720p':\n",
    "\n",
    "                #get the video url\n",
    "                url = f.get('url',None)\n",
    "                \n",
    "                # open url with opencv\n",
    "                cap = cv2.VideoCapture(url)\n",
    "                # check if url was opened\n",
    "                if not cap.isOpened():\n",
    "                    print('Error: Video not opened')\n",
    "                    continue\n",
    "\n",
    "                #Initialize object tracking arrays\n",
    "                #Start frame count\n",
    "                frame_count = 0\n",
    "                while True:\n",
    "                    # modulo variable\n",
    "                    M = 0\n",
    "                    \n",
    "                    # read frame\n",
    "                    ret, frame = cap.read()\n",
    "                    \n",
    "                    #Start Frame Counting\n",
    "                    frame_count = frame_count + 1\n",
    "                    \n",
    "                    # check if frame is empty\n",
    "                    if not ret:\n",
    "                        print('No frame found')\n",
    "                        break\n",
    "                    \n",
    "                    #Script that clears up the trackers every N frames so the faceNet can happen\n",
    "                    if not skip_frames == 0:\n",
    "                        if (frame_count%skip_frames) == 0:\n",
    "                        #Clear up  face tracker\n",
    "                            face_tracker = []\n",
    "                        \n",
    "                    if detect:\n",
    "                        #Pass frames into which Detector Type\n",
    "                        if self.faceNetType in ['ResCaffe','SFD']:\n",
    "                            \n",
    "                            face_box = detect_face(frame, self.faceNet)\n",
    "                            if face_box is None:\n",
    "                                continue\n",
    "                            results = detect_mask(face_box, frame, self.maskNet,save)\n",
    "                       \n",
    "                        elif self.faceNetType in ['fastMTCNN','stdMTCNN']:\n",
    "                    \n",
    "                            #Detect face #Bit of a heavy operation\n",
    "                            face_box = detect_face_MTCNN(frame, self.faceNet, draw)\n",
    "                            \n",
    "                            #If no faces are detected go back to start, but before that, update the latest frame\n",
    "                            if face_box is None:\n",
    "                                print(\"No face Detected 4\")\n",
    "                                continue\n",
    "                            results = detect_mask(face_box, frame, self.maskNet, save)\n",
    "                            \n",
    "                    if save_vid:\n",
    "                        cv2.imwrite(\"misc/vidimages/\"+str(frame_count)+\".jpg\", frame)  # save frame as JPG file\n",
    "                        print()\n",
    "                        print('saving frame')\n",
    "                        \n",
    "                    # display frame\n",
    "                    \n",
    "                    cv2.imshow('frame', frame)\n",
    "                    key = cv2.waitKey(1) & 0xFF\n",
    "                    if key == ord(\"q\"):\n",
    "                        cap.release()\n",
    "                        cv2.destroyAllWindows()\n",
    "                        return\n",
    "\n",
    "                # release VideoCapture\n",
    "                cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing\n",
      "stdMTCNN initialized as the Detection\n",
      "[youtube] 7Yiq_g0bGjk: Downloading webpage\n",
      "Face Detection Inference is:0.029978036880493164\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.031966209411621094\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.03197979927062988\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.030981779098510742\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.015627145767211914\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.038748741149902344\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.028980731964111328\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.03126692771911621\n",
      "Mask Inference:0.0230s\n",
      "Face Detection Inference is:0.015623092651367188\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.03124833106994629\n",
      "Mask Inference:0.0254s\n",
      "Face Detection Inference is:0.04099154472351074\n",
      "Mask Inference:0.0279s\n",
      "Face Detection Inference is:0.0312502384185791\n",
      "Mask Inference:0.0263s\n",
      "Face Detection Inference is:0.015624046325683594\n",
      "Mask Inference:0.0263s\n",
      "Face Detection Inference is:0.030979633331298828\n",
      "Mask Inference:0.0254s\n",
      "Face Detection Inference is:0.027762889862060547\n",
      "No face detected\n",
      "No face Detected 4\n",
      "Face Detection Inference is:0.03125476837158203\n",
      "Mask Inference:0.0235s\n",
      "Face Detection Inference is:0.035428762435913086\n",
      "Mask Inference:0.0265s\n"
     ]
    }
   ],
   "source": [
    "vid =vidPlayer('https://www.youtube.com/watch?v=7Yiq_g0bGjk',faceNet = 'stdMTCNN')\n",
    "#https://www.youtube.com/watch?v=AYrTp08p5Cs American Protest\n",
    "#https://www.youtube.com/watch?v=bVPAAvfpw9U Philippine Market \n",
    "#https://www.youtube.com/watch?v=YbSqC1r0nUc Philippine News Report Video\n",
    "#https://www.youtube.com/watch?v=g-dyHadto2Y&t=38s\n",
    "#vid =vidPlayer('https://www.youtube.coqqm/watch?v=Um0Z7Lo_jHs',faceNet = 'MTCNN')\n",
    "#https://www.youtube.com/watch?v=_xA57XCjAtI high res?\n",
    "#https://www.youtube.com/watch?v=ShlI5_sR2do\n",
    "#https://www.youtube.com/watch?v=_wox36bFDqE\n",
    "#https://www.youtube.com/watch?v=2xLjCfmx0iE\n",
    "#Add in argument save = True If you want to save images classified into folders of withMask or NoMask\n",
    "#https://www.youtube.com/watch?v=7Yiq_g0bGjk Good Diverse Video of the Philippines\n",
    "#vid.youtube_play(detect=1, draw = False, save = True, skip_frames = 30)\n",
    "vid.youtube_play(detect=1, draw = True, save = False, skip_frames = 0, save_vid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
